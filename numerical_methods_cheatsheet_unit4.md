# ğŸ¯ NUMERICAL METHODS COMPLETE CHEATSHEET
## UNIT 4: Ordinary & Partial Differential Equations

---

# ğŸ“š PART A: ORDINARY DIFFERENTIAL EQUATIONS (ODEs)

---

## 1. INTRODUCTION TO NUMERICAL ODE METHODS

### ğŸ§  Intuition First

A differential equation describes HOW a quantity changes. For example:
- dy/dx = 2x means "y changes at rate 2x"
- Given y(0) = 1, what is y(3)?

Often we can't solve analytically, so we "march forward" in small steps, predicting the next value from the current one.

### ğŸ“ Standard Form: Initial Value Problem (IVP)

```
dy/dx = f(x, y)
y(xâ‚€) = yâ‚€
```

**Goal**: Find y(x) for x > xâ‚€

### ğŸ“ Classification of Methods

| Type | Description | Examples |
|------|-------------|----------|
| Single-step | Uses only current point | Euler, Runge-Kutta |
| Multi-step | Uses several previous points | Adams, Milne |
| Predictor-Corrector | Predict then refine | Adams-Moulton |
| Explicit | yâ‚™â‚Šâ‚ computed directly | Forward Euler |
| Implicit | yâ‚™â‚Šâ‚ appears on both sides | Backward Euler |

---

## 2. PICARD'S METHOD (Successive Approximation)

### ğŸ§  Intuition First

Start with a guess for y(x), plug it into the differential equation, integrate to get a better guess. Repeat until convergence!

### ğŸ“ The Method

Transform dy/dx = f(x,y), y(xâ‚€) = yâ‚€ into integral form:

```
y(x) = yâ‚€ + âˆ«â‚“â‚€Ë£ f(t, y(t)) dt
```

**Iteration**:
```
yâ½â°â¾(x) = yâ‚€  (initial guess - constant)
yâ½â¿âºÂ¹â¾(x) = yâ‚€ + âˆ«â‚“â‚€Ë£ f(t, yâ½â¿â¾(t)) dt
```

### ğŸ“Š Worked Example

Solve: dy/dx = x + y, y(0) = 1

**Iteration 0**: yâ½â°â¾ = 1

**Iteration 1**:
```
yâ½Â¹â¾ = 1 + âˆ«â‚€Ë£ (t + 1) dt = 1 + [tÂ²/2 + t]â‚€Ë£ = 1 + xÂ²/2 + x
```

**Iteration 2**:
```
yâ½Â²â¾ = 1 + âˆ«â‚€Ë£ (t + 1 + tÂ²/2 + t) dt
     = 1 + âˆ«â‚€Ë£ (1 + 2t + tÂ²/2) dt
     = 1 + x + xÂ² + xÂ³/6
```

**Iteration 3**:
```
yâ½Â³â¾ = 1 + x + xÂ² + xÂ³/3 + xâ´/24
```

Pattern: Approaches y = 2eË£ - x - 1 (exact solution!)

### âš ï¸ Limitations

1. **Tedious integration** required at each step
2. **Slow convergence** for many problems
3. **Theoretical importance** but rarely used in practice

### ğŸ’¡ Memory Trick
**"Picard = Plug In, Calculate Integral, Repeat, Done (eventually)"**

---

## 3. TAYLOR SERIES METHOD

### ğŸ§  Intuition First

Use Taylor series to predict y at the next step, computing higher derivatives from the differential equation itself.

### ğŸ“ The Method

Expand y(x+h) around x:
```
y(x+h) = y(x) + hy'(x) + (hÂ²/2!)y''(x) + (hÂ³/3!)y'''(x) + ...
```

From dy/dx = f(x,y), we get:
```
y' = f(x,y)
y'' = df/dx = âˆ‚f/âˆ‚x + (âˆ‚f/âˆ‚y)(dy/dx) = fâ‚“ + fÂ·fáµ§
y''' = dÂ²f/dxÂ² = ... (chain rule, more complex)
```

### ğŸ“ Taylor Series of Order p

```
yâ‚™â‚Šâ‚ = yâ‚™ + hf + (hÂ²/2!)f' + ... + (háµ–/p!)fâ½áµ–â»Â¹â¾
```

**Truncation Error**: O(háµ–âºÂ¹)

### ğŸ“Š Worked Example

Solve: dy/dx = x + y, y(0) = 1, find y(0.1) using 3rd order Taylor

At x = 0, y = 1:
```
y' = f = x + y = 0 + 1 = 1
y'' = 1 + y' = 1 + 1 = 2
y''' = y'' = 2
```

```
y(0.1) = 1 + (0.1)(1) + (0.01/2)(2) + (0.001/6)(2)
       = 1 + 0.1 + 0.01 + 0.00033
       = 1.11033
```

Exact: y = 2eâ°Â·Â¹ - 0.1 - 1 = 1.11034 âœ“

### âš ï¸ Limitations

1. **Derivatives become complex** for high orders
2. **Tedious for complicated f(x,y)**
3. Works well when derivatives are easy to compute

---

## 4. EULER'S METHOD (Forward Euler)

### ğŸ§  Intuition First

The simplest possible method! Just follow the tangent line from current point to the next.

Like driving while only looking at the direction of your steering wheel - you go straight in that direction for a small distance.

### ğŸ“ The Formula

```
yâ‚™â‚Šâ‚ = yâ‚™ + hÂ·f(xâ‚™, yâ‚™)
```

This is Taylor series truncated after the LINEAR term!

### ğŸ¨ Visual Understanding

```
    True solution
        ___---
    ___/   
   /    Euler approximation (tangent)
  /   ___----
 /___/
â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—
xâ‚™         xâ‚™â‚Šâ‚
```

We follow the tangent, which drifts away from the true curve.

### ğŸ“ Algorithm

```
Input: f, xâ‚€, yâ‚€, h, N (number of steps)

For n = 0, 1, ..., N-1:
    xâ‚™â‚Šâ‚ = xâ‚™ + h
    yâ‚™â‚Šâ‚ = yâ‚™ + h Ã— f(xâ‚™, yâ‚™)
    
Return sequence (xâ‚™, yâ‚™)
```

### ğŸ“Š Worked Example

Solve: dy/dx = x + y, y(0) = 1, find y(0.2) with h = 0.1

| n | xâ‚™ | yâ‚™ | f(xâ‚™,yâ‚™)=xâ‚™+yâ‚™ | yâ‚™â‚Šâ‚ = yâ‚™ + 0.1f |
|---|-----|------|------------------|------------------|
| 0 | 0 | 1 | 1 | 1.1 |
| 1 | 0.1 | 1.1 | 1.2 | 1.22 |
| 2 | 0.2 | 1.22 | | |

So y(0.2) â‰ˆ 1.22

Exact: y(0.2) = 2eâ°Â·Â² - 0.2 - 1 â‰ˆ 1.2428

Error â‰ˆ 0.023

### ğŸ“ Error Analysis

**Local Truncation Error** (error in one step, assuming no prior error):
```
LTE = |y(xâ‚™â‚Šâ‚) - yâ‚™â‚Šâ‚| = O(hÂ²)
```

**Global Error** (accumulated error after N steps where Nh = constant):
```
GE = O(h)
```

Why? N âˆ 1/h, so N Ã— LTE = (1/h) Ã— hÂ² = h

**Euler is a first-order method**: Global error O(h)

### âš ï¸ Stability Issues

For the test equation y' = Î»y:
- Euler is stable only if |1 + Î»h| < 1
- For Î» < 0 (decay): need h < 2/|Î»|
- For stiff equations (large |Î»|): tiny h required!

### ğŸ’¡ Memory Trick
**"Euler = Easy + Erroneous (simple but inaccurate)"**

---

## 5. RUNGE-KUTTA METHODS

### ğŸ§  Intuition First

Euler uses the slope at the START of the interval. What if we sampled the slope at MULTIPLE points and averaged them? This is the Runge-Kutta idea!

Like navigating by checking your compass several times along the way, not just at the start.

### ğŸ“ General Runge-Kutta Form

```
yâ‚™â‚Šâ‚ = yâ‚™ + h Ã— (weighted average of slope estimates)
```

### ğŸ“ Midpoint Method (RK2)

**Idea**: Use slope at the MIDPOINT of the interval

```
kâ‚ = f(xâ‚™, yâ‚™)
kâ‚‚ = f(xâ‚™ + h/2, yâ‚™ + (h/2)kâ‚)
yâ‚™â‚Šâ‚ = yâ‚™ + hÂ·kâ‚‚
```

**Order**: 2 (Global error O(hÂ²))

### ğŸ“ Heun's Method (Improved Euler / RK2 variant)

```
kâ‚ = f(xâ‚™, yâ‚™)
kâ‚‚ = f(xâ‚™ + h, yâ‚™ + hÂ·kâ‚)
yâ‚™â‚Šâ‚ = yâ‚™ + (h/2)(kâ‚ + kâ‚‚)
```

Average of slopes at start and (predicted) end.

### ğŸ“ Classical 4th Order Runge-Kutta (RK4) â­

**THE most widely used method!**

```
kâ‚ = f(xâ‚™, yâ‚™)
kâ‚‚ = f(xâ‚™ + h/2, yâ‚™ + (h/2)kâ‚)
kâ‚ƒ = f(xâ‚™ + h/2, yâ‚™ + (h/2)kâ‚‚)
kâ‚„ = f(xâ‚™ + h, yâ‚™ + hÂ·kâ‚ƒ)

yâ‚™â‚Šâ‚ = yâ‚™ + (h/6)(kâ‚ + 2kâ‚‚ + 2kâ‚ƒ + kâ‚„)
```

**Memory device**: Weights are 1-2-2-1, divide by 6

### ğŸ“Š Worked Example (RK4)

Solve: dy/dx = x + y, y(0) = 1, find y(0.1) with h = 0.1

```
kâ‚ = f(0, 1) = 0 + 1 = 1
kâ‚‚ = f(0.05, 1 + 0.05Ã—1) = f(0.05, 1.05) = 1.1
kâ‚ƒ = f(0.05, 1 + 0.05Ã—1.1) = f(0.05, 1.055) = 1.105
kâ‚„ = f(0.1, 1 + 0.1Ã—1.105) = f(0.1, 1.1105) = 1.2105

y(0.1) = 1 + (0.1/6)(1 + 2(1.1) + 2(1.105) + 1.2105)
       = 1 + (0.1/6)(6.6205)
       = 1 + 0.11034
       = 1.11034
```

Exact: 1.11034 - EXCELLENT agreement!

### ğŸ“ Error Analysis for RK4

**Local Truncation Error**: O(hâµ)
**Global Error**: O(hâ´)

RK4 is a **fourth-order method** - very accurate!

### ğŸ“ Computational Cost

| Method | Order | f evaluations per step |
|--------|-------|----------------------|
| Euler | 1 | 1 |
| RK2 (Midpoint) | 2 | 2 |
| RK4 (Classical) | 4 | 4 |

RK4 gives 4th order accuracy for 4 function evaluations - very efficient!

### ğŸ’¡ Memory Trick for RK4
**"k's at 0, 1/2, 1/2, 1 of the step; weights 1-2-2-1; divide by 6"**

---

## 6. PREDICTOR-CORRECTOR METHODS

### ğŸ§  Intuition First

Two-phase approach:
1. **PREDICT**: Make a rough estimate using an explicit formula
2. **CORRECT**: Improve the estimate using an implicit formula

Like making a first draft, then editing it!

### ğŸ“ Euler's Predictor-Corrector (Modified Euler)

**Predictor** (Forward Euler):
```
á»¹â‚™â‚Šâ‚ = yâ‚™ + hÂ·f(xâ‚™, yâ‚™)
```

**Corrector** (Trapezoidal rule):
```
yâ‚™â‚Šâ‚ = yâ‚™ + (h/2)[f(xâ‚™, yâ‚™) + f(xâ‚™â‚Šâ‚, á»¹â‚™â‚Šâ‚)]
```

Can iterate the corrector for better accuracy!

### ğŸ“ Order and Properties

- **Order 2** (same as RK2)
- More accurate than pure Euler
- Uses information from both ends of interval

---

## 7. ADAMS-BASHFORTH METHOD (Multi-step)

### ğŸ§  Intuition First

Why compute f at the current point only? Use the history! If you know how f has been behaving over the last few steps, you can predict the future better.

### ğŸ“ General Idea

Multi-step methods use values from previous steps:
```
yâ‚™â‚Šâ‚ = yâ‚™ + h Ã— (combination of fâ‚™, fâ‚™â‚‹â‚, fâ‚™â‚‹â‚‚, ...)
```

### ğŸ“ Adams-Bashforth Formulas (Explicit)

**2-step (AB2)**:
```
yâ‚™â‚Šâ‚ = yâ‚™ + (h/2)(3fâ‚™ - fâ‚™â‚‹â‚)
```

**3-step (AB3)**:
```
yâ‚™â‚Šâ‚ = yâ‚™ + (h/12)(23fâ‚™ - 16fâ‚™â‚‹â‚ + 5fâ‚™â‚‹â‚‚)
```

**4-step (AB4)**:
```
yâ‚™â‚Šâ‚ = yâ‚™ + (h/24)(55fâ‚™ - 59fâ‚™â‚‹â‚ + 37fâ‚™â‚‹â‚‚ - 9fâ‚™â‚‹â‚ƒ)
```

Where fâ±¼ = f(xâ±¼, yâ±¼)

### ğŸ“ Starting Values

**Problem**: AB methods need yâ‚€, yâ‚, ..., yâ‚–â‚‹â‚ to start!

**Solution**: Use RK4 or another single-step method to compute starting values.

### ğŸ“ Adams-Moulton Formulas (Implicit)

**2-step (AM2 = Trapezoidal)**:
```
yâ‚™â‚Šâ‚ = yâ‚™ + (h/2)(fâ‚™â‚Šâ‚ + fâ‚™)
```

**3-step (AM3)**:
```
yâ‚™â‚Šâ‚ = yâ‚™ + (h/12)(5fâ‚™â‚Šâ‚ + 8fâ‚™ - fâ‚™â‚‹â‚)
```

### ğŸ“ Adams Predictor-Corrector

**Predictor**: Adams-Bashforth (explicit)
**Corrector**: Adams-Moulton (implicit)

Example (ABM4):
```
Predict: á»¹â‚™â‚Šâ‚ = yâ‚™ + (h/24)(55fâ‚™ - 59fâ‚™â‚‹â‚ + 37fâ‚™â‚‹â‚‚ - 9fâ‚™â‚‹â‚ƒ)
Correct: yâ‚™â‚Šâ‚ = yâ‚™ + (h/24)(9fÌƒâ‚™â‚Šâ‚ + 19fâ‚™ - 5fâ‚™â‚‹â‚ + fâ‚™â‚‹â‚‚)
```
where fÌƒâ‚™â‚Šâ‚ = f(xâ‚™â‚Šâ‚, á»¹â‚™â‚Šâ‚)

---

## 8. MILNE'S METHOD

### ğŸ“ The Formulas

**Milne's Predictor** (uses 4 past values):
```
á»¹â‚™â‚Šâ‚ = yâ‚™â‚‹â‚ƒ + (4h/3)(2fâ‚™ - fâ‚™â‚‹â‚ + 2fâ‚™â‚‹â‚‚)
```

**Milne's Corrector**:
```
yâ‚™â‚Šâ‚ = yâ‚™â‚‹â‚ + (h/3)(fâ‚™â‚Šâ‚ + 4fâ‚™ + fâ‚™â‚‹â‚)
```

The corrector is Simpson's rule!

### ğŸ“ Order

Milne's method is **4th order** (like RK4).

### âš ï¸ Stability Issue

Milne's method is **weakly unstable**: small errors can grow over time, even for stable problems!

For long integrations, Adams methods are preferred.

---

# ğŸ“š PART B: PARTIAL DIFFERENTIAL EQUATIONS (PDEs)

---

## 9. CLASSIFICATION OF PDEs

### ğŸ“ Second-Order Linear PDEs

General form:
```
AÂ·uâ‚“â‚“ + BÂ·uâ‚“áµ§ + CÂ·uáµ§áµ§ + DÂ·uâ‚“ + EÂ·uáµ§ + FÂ·u = G
```

**Classification** (based on discriminant BÂ² - 4AC):

| Type | Condition | Example | Physical Meaning |
|------|-----------|---------|------------------|
| **Elliptic** | BÂ² - 4AC < 0 | Laplace: uâ‚“â‚“ + uáµ§áµ§ = 0 | Steady-state, equilibrium |
| **Parabolic** | BÂ² - 4AC = 0 | Heat: uâ‚œ = Î±Â·uâ‚“â‚“ | Diffusion, time evolution |
| **Hyperbolic** | BÂ² - 4AC > 0 | Wave: uâ‚œâ‚œ = cÂ²Â·uâ‚“â‚“ | Waves, vibrations |

### ğŸ’¡ Memory Trick
**"Elliptic = Equilibrium, Parabolic = Heat, Hyperbolic = Waves"**

---

## 10. PARABOLIC EQUATIONS (Heat Equation)

### ğŸ“ The Heat Equation

```
âˆ‚u/âˆ‚t = Î± Â· âˆ‚Â²u/âˆ‚xÂ²
```

With initial condition u(x, 0) = f(x) and boundary conditions.

### ğŸ“ Discretization

**Grid**: Points (xáµ¢, tâ±¼) where xáµ¢ = ih, tâ±¼ = jk

**Notation**: uáµ¢Ê² â‰ˆ u(xáµ¢, tâ±¼)

**Finite Differences**:
```
âˆ‚u/âˆ‚t â‰ˆ (uáµ¢Ê²âºÂ¹ - uáµ¢Ê²)/k  (forward in time)
âˆ‚Â²u/âˆ‚xÂ² â‰ˆ (uáµ¢â‚Šâ‚Ê² - 2uáµ¢Ê² + uáµ¢â‚‹â‚Ê²)/hÂ²  (central in space)
```

### ğŸ“ Explicit Method (FTCS)

Forward Time, Central Space:

```
uáµ¢Ê²âºÂ¹ = uáµ¢Ê² + r(uáµ¢â‚Šâ‚Ê² - 2uáµ¢Ê² + uáµ¢â‚‹â‚Ê²)
```

Where r = Î±k/hÂ² (mesh ratio)

**Rearranged**:
```
uáµ¢Ê²âºÂ¹ = rÂ·uáµ¢â‚‹â‚Ê² + (1-2r)Â·uáµ¢Ê² + rÂ·uáµ¢â‚Šâ‚Ê²
```

### ğŸ“ Stability Condition

**CRITICAL**: The explicit method is stable only if:
```
r = Î±k/hÂ² â‰¤ 1/2
```

If violated, the solution will oscillate wildly and blow up!

### ğŸ“ Implicit Method (Backward Euler)

```
uáµ¢Ê²âºÂ¹ - r(uáµ¢â‚Šâ‚Ê²âºÂ¹ - 2uáµ¢Ê²âºÂ¹ + uáµ¢â‚‹â‚Ê²âºÂ¹) = uáµ¢Ê²
```

This is a tridiagonal system! Solve using Thomas algorithm.

**Advantage**: Unconditionally stable (any r)!

### ğŸ“ Crank-Nicolson Method

Average of explicit and implicit (most popular!):

```
uáµ¢Ê²âºÂ¹ - (r/2)(uáµ¢â‚Šâ‚Ê²âºÂ¹ - 2uáµ¢Ê²âºÂ¹ + uáµ¢â‚‹â‚Ê²âºÂ¹) = 
uáµ¢Ê² + (r/2)(uáµ¢â‚Šâ‚Ê² - 2uáµ¢Ê² + uáµ¢â‚‹â‚Ê²)
```

**Properties**:
- Unconditionally stable
- Second-order accurate in both time and space: O(kÂ² + hÂ²)
- Solves a tridiagonal system per time step

### ğŸ’¡ Memory Trick
**"Explicit = Easy but unstable; Implicit = Stable but solve system; Crank-Nicolson = Best of both!"**

---

## 11. HYPERBOLIC EQUATIONS (Wave Equation)

### ğŸ“ The Wave Equation

```
âˆ‚Â²u/âˆ‚tÂ² = cÂ² Â· âˆ‚Â²u/âˆ‚xÂ²
```

With initial conditions u(x,0) = f(x), uâ‚œ(x,0) = g(x)

### ğŸ“ Explicit Finite Difference Scheme

```
uáµ¢Ê²âºÂ¹ = 2uáµ¢Ê² - uáµ¢Ê²â»Â¹ + Î»Â²(uáµ¢â‚Šâ‚Ê² - 2uáµ¢Ê² + uáµ¢â‚‹â‚Ê²)
```

Where Î» = ck/h (Courant number)

### ğŸ“ Stability Condition (CFL)

**Courant-Friedrichs-Lewy (CFL) condition**:
```
Î» = ck/h â‰¤ 1
```

**Physical meaning**: The numerical domain of dependence must contain the physical domain of dependence.

### ğŸ“ Starting the Method

Need u at j = 0 AND j = 1 to start!

For j = 1, use initial conditions:
```
u(x, k) â‰ˆ u(x, 0) + kÂ·uâ‚œ(x, 0) = f(x) + kÂ·g(x)
```

Or more accurately:
```
uáµ¢Â¹ = (1-Î»Â²)f(xáµ¢) + (Î»Â²/2)[f(xáµ¢â‚Šâ‚) + f(xáµ¢â‚‹â‚)] + kÂ·g(xáµ¢)
```

---

## 12. ELLIPTIC EQUATIONS (Laplace/Poisson)

### ğŸ“ Laplace's Equation

```
âˆ‚Â²u/âˆ‚xÂ² + âˆ‚Â²u/âˆ‚yÂ² = 0  (Laplace)
âˆ‚Â²u/âˆ‚xÂ² + âˆ‚Â²u/âˆ‚yÂ² = f(x,y)  (Poisson)
```

**Physical meaning**: Steady-state temperature, potential fields, equilibrium distributions.

### ğŸ“ Five-Point Formula

Discretize on a grid with spacing h:

```
uáµ¢â‚Šâ‚,â±¼ + uáµ¢â‚‹â‚,â±¼ + uáµ¢,â±¼â‚Šâ‚ + uáµ¢,â±¼â‚‹â‚ - 4uáµ¢,â±¼ = hÂ²fáµ¢,â±¼
```

Or for Laplace (f = 0):
```
uáµ¢,â±¼ = (uáµ¢â‚Šâ‚,â±¼ + uáµ¢â‚‹â‚,â±¼ + uáµ¢,â±¼â‚Šâ‚ + uáµ¢,â±¼â‚‹â‚)/4
```

**The value at each interior point is the AVERAGE of its four neighbors!**

### ğŸ“ Solution Methods

**Direct Methods**: Form the big linear system, solve with LU decomposition
- For N interior points: NÃ—N system!

**Iterative Methods** (preferred for large problems):

**Jacobi Iteration**:
```
uáµ¢,â±¼â½â¿âºÂ¹â¾ = (uáµ¢â‚Šâ‚,â±¼â½â¿â¾ + uáµ¢â‚‹â‚,â±¼â½â¿â¾ + uáµ¢,â±¼â‚Šâ‚â½â¿â¾ + uáµ¢,â±¼â‚‹â‚â½â¿â¾)/4
```
All updates use OLD values only.

**Gauss-Seidel Iteration**:
```
uáµ¢,â±¼â½â¿âºÂ¹â¾ = (uáµ¢â‚Šâ‚,â±¼â½â¿â¾ + uáµ¢â‚‹â‚,â±¼â½â¿âºÂ¹â¾ + uáµ¢,â±¼â‚Šâ‚â½â¿â¾ + uáµ¢,â±¼â‚‹â‚â½â¿âºÂ¹â¾)/4
```
Use NEW values as soon as available - converges faster!

**SOR (Successive Over-Relaxation)**:
```
uáµ¢,â±¼â½â¿âºÂ¹â¾ = (1-Ï‰)uáµ¢,â±¼â½â¿â¾ + Ï‰ Ã— (Gauss-Seidel update)
```
Where 1 < Ï‰ < 2 (optimal Ï‰ depends on problem)

### ğŸ“ Convergence

| Method | Convergence Rate |
|--------|-----------------|
| Jacobi | Slow |
| Gauss-Seidel | 2Ã— faster than Jacobi |
| SOR (optimal Ï‰) | Much faster |

---

# ğŸ“Š UNIT 4 SUMMARY TABLE

| Method | Type | Order | Key Feature | Best For |
|--------|------|-------|-------------|----------|
| Picard | ODE | - | Theoretical | Understanding |
| Taylor | ODE | p (chosen) | Uses derivatives | Simple f(x,y) |
| Euler | ODE | 1 | Simplest | Teaching, rough estimates |
| RK2 | ODE | 2 | 2 evaluations | Moderate accuracy |
| RK4 | ODE | 4 | 4 evaluations | **Most practical** |
| Adams-Bashforth | ODE (multi) | 1-4 | Uses history | Long integrations |
| Milne | ODE (multi) | 4 | Simpson-like | Not recommended (unstable) |
| FTCS (Explicit) | Heat PDE | 1 | Simple | When r â‰¤ 0.5 |
| Implicit | Heat PDE | 1 | Always stable | Stiff problems |
| Crank-Nicolson | Heat PDE | 2 | Best accuracy | **Most practical** |
| Explicit | Wave PDE | 2 | Simple | When Î» â‰¤ 1 |
| Five-point | Elliptic | 2 | Averaging | Laplace/Poisson |

---

# ğŸ¯ EXAM CHECKLIST - UNIT 4

## ODEs
â–¡ Can apply Picard's iteration for one or two steps?
â–¡ Know Euler's formula: yâ‚™â‚Šâ‚ = yâ‚™ + hf?
â–¡ Can derive local and global error order of Euler?
â–¡ Know RK4 formula (kâ‚, kâ‚‚, kâ‚ƒ, kâ‚„ and weights)?
â–¡ Can compute one step of RK4?
â–¡ Understand predictor-corrector concept?
â–¡ Know Adams-Bashforth is multi-step, needs starting values?

## PDEs
â–¡ Can classify PDE as elliptic/parabolic/hyperbolic?
â–¡ Know heat equation discretization (explicit/implicit)?
â–¡ Know stability condition r â‰¤ 1/2 for explicit heat?
â–¡ Know wave equation stability condition Î» â‰¤ 1?
â–¡ Know five-point formula for Laplace?
â–¡ Understand Jacobi vs Gauss-Seidel iteration?

---

# ğŸ† GRAND SUMMARY: ALL UNITS

## Key Formulas to MEMORIZE

### Unit 1
- Taylor: f(x) = Î£ fâ½â¿â¾(a)(x-a)â¿/n!
- Newton: xâ‚™â‚Šâ‚ = xâ‚™ - f(xâ‚™)/f'(xâ‚™)
- Secant: xâ‚™â‚Šâ‚ = xâ‚™ - f(xâ‚™)(xâ‚™-xâ‚™â‚‹â‚)/(f(xâ‚™)-f(xâ‚™â‚‹â‚))

### Unit 2
- Lagrange: P(x) = Î£ yáµ¢Láµ¢(x)
- Trapezoidal: âˆ« â‰ˆ h[fâ‚€ + 2fâ‚ + ... + 2fâ‚™â‚‹â‚ + fâ‚™]/2
- Simpson: âˆ« â‰ˆ h[fâ‚€ + 4fâ‚ + 2fâ‚‚ + 4fâ‚ƒ + ... + fâ‚™]/3

### Unit 3
- Gauss: Forward elimination â†’ Back substitution
- LU: A = LU, then Ly = b, Ux = y
- Power: xâ½áµâ¾ = Axâ½áµâ»Â¹â¾/||Axâ½áµâ»Â¹â¾||

### Unit 4
- Euler: yâ‚™â‚Šâ‚ = yâ‚™ + hf(xâ‚™,yâ‚™)
- RK4: yâ‚™â‚Šâ‚ = yâ‚™ + h(kâ‚ + 2kâ‚‚ + 2kâ‚ƒ + kâ‚„)/6
- Heat explicit: uáµ¢Ê²âºÂ¹ = rÂ·uáµ¢â‚‹â‚Ê² + (1-2r)Â·uáµ¢Ê² + rÂ·uáµ¢â‚Šâ‚Ê²

## Error Orders Quick Reference

| Method | Error Order |
|--------|-------------|
| Bisection | O(1/2â¿) - linear |
| Newton | O(eâ‚™Â²) - quadratic |
| Secant | O(eâ‚™^1.618) |
| Trapezoidal | O(hÂ²) |
| Simpson 1/3 | O(hâ´) |
| Gauss Quadrature (n pts) | O(h^2n) |
| Euler | O(h) |
| RK4 | O(hâ´) |

## When to Use What

| Problem | Best Method |
|---------|-------------|
| Root finding, have f' | Newton |
| Root finding, no f' | Secant or Bisection |
| Integration, smooth function | Simpson or Gaussian |
| Interpolation, equally spaced | Newton Forward/Backward |
| Interpolation, unequal spacing | Lagrange or Divided Diff |
| Linear system, one RHS | Gauss elimination |
| Linear system, multiple RHS | LU decomposition |
| ODE, general purpose | RK4 |
| Heat equation | Crank-Nicolson |
| Laplace equation | SOR iteration |

---

# ğŸ’ª FINAL EXAM TIPS

1. **Show ALL Steps**: Partial credit for methodology!
2. **State Formulas First**: Write the formula before plugging in numbers
3. **Check Conditions**: Note assumptions (converges if..., stable if...)
4. **Organize Tables**: Use neat tables for iterative methods
5. **Error Analysis**: Always mention error order when asked
6. **Units and Precision**: Carry enough decimal places
7. **Verify When Possible**: Substitute answer back to check
8. **Time Management**: Don't get stuck on one problem

**GOOD LUCK! ğŸ¯**
